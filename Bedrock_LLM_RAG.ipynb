{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d01f727",
   "metadata": {},
   "source": [
    "#### Step 1 : Import Required Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bcaf5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import required Libs\n",
    "import boto3\n",
    "import json\n",
    "from botocore.exceptions import BotoCoreError, ClientError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255ad0f9",
   "metadata": {},
   "source": [
    "#### Step 2 : Set AWS Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3de5e4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Environment is setup successfully\n"
     ]
    }
   ],
   "source": [
    "## Set AWS Region\n",
    "try:\n",
    "    # Set AWS Region\n",
    "    region = \"us-east-1\"  # Note the correct region code \"us-east-1\"\n",
    "    \n",
    "    # The Bedrock runtime must be initialized with your AWS credentials/profile and region to authenticate you \n",
    "    # and direct requests to the right foundation models or agent.\n",
    "    bedrock_runtime = boto3.client(\"bedrock-runtime\", region_name=region)\n",
    "    s3 = boto3.client(\"s3\", region_name=region)\n",
    "    \n",
    "    print(\"Project Environment is setup successfully\")\n",
    "    \n",
    "except (BotoCoreError, ClientError) as error:\n",
    "    print(f\"An error occurred while setting up AWS clients: {error}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5d78ad",
   "metadata": {},
   "source": [
    "#### Step-3 : Setup RAG Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a3fe83",
   "metadata": {},
   "source": [
    "###### 1. Take user query\n",
    "###### 2. Retrieve relevant information from our knowledge base\n",
    "###### 3. Generate a response using a foundation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6323fcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##--------------------------------------------------------------------------------------------------------------------------------------------- \n",
    "## 1] RAG Model - Amazon Titan text foundation model available via Amazon Bedrock.\n",
    "##  This model is a large language model (LLM) optimized for a wide range of advanced, general-purpose language\n",
    "##  tasks such as open-ended text generation, conversational chat, and also supports Retrieval Augmented Generation (RAG) workflows.\n",
    "##  ---\n",
    "## 2] knowledge_base_id identifies the knowledge base to query.This is a unique identifier (typically a string or an Amazon Resource Name, ARN)\n",
    "##  that specifies which knowledge base your application or model should access during information retrieval.\n",
    "##  In the context of Amazon Bedrock: A knowledge base is a structured repository of information—often created by ingesting private documents,\n",
    "##  databases, or other content. Amazon Bedrock uses these knowledge bases to support Retrieval-Augmented Generation (RAG) workflows.\n",
    "##  The knowledge_base_id is the unique ID assigned to a specific knowledge base within Amazon Bedrock. When issuing a query,\n",
    "##  this ID tells Bedrock which knowledge base to search for relevant information.\n",
    "##---------------------------------------------------------------------------------------------------------------------------------------------\n",
    "##\n",
    "model_id = \"amazon.titan-text-express-v1\"\n",
    "def generate_rag_response(query,knowledge_base_id, model_id = model_id):\n",
    "    \"\"\" Generate Response using RAG Approach\n",
    "        Args :\n",
    "         1] query (str) : The user's question\n",
    "         2] knowledge_base_id (str) : ID of the knowledge base to query\n",
    "    \"\"\"\n",
    "    try: \n",
    "        \"\"\" Step-1 : Retrieve information from the knowledge base\n",
    "        # Note : In a full implemenation, we would call the Bedrock Knowledge Base API here\n",
    "        # For this example, we will simulate the retrieval with a placeholder\n",
    "        # bedrock_agent_runtime = boto3.client('bedrock-agent-runtime', region_name = region)\n",
    "        # kb_response = bedrock_agent_runtime.retrieve(\n",
    "           knowledgeBaseId=knowledge_base_id,\n",
    "           retrivalQuery ={'text' : query},\n",
    "           numberOfResults = 3)\n",
    "       \"\"\"\n",
    "       ## For simplified example:\n",
    "        retrieved_info =\"\"\" Employee Handbook Section 3.2 : Pait Time Off\n",
    "         All Employees accrue PTO at a rate of 1.5 days per month (18 days per year).\n",
    "         PTO requests must be submitted at least two weeks in advance through the HR portal\n",
    "         Unused PTO can be carried over to the following year, up to a maximum of 5 days\n",
    "         For further queries on PTO, please contact hr@example.com\n",
    "\n",
    "         Remote work policy for full time employees only - Full time employees are eligible to work remotely \n",
    "         up to 2 days per week and max of 10 days per month under unavoidable circumstances only when manager \n",
    "         has approved additional remote work days. Under normal circumstances, full time employees are expected to work from office for 3 days a week.\n",
    "         For consitency, co-ordination and efficiency purpose, all employees are expected to work from\n",
    "         office from Monday to Wednesday.\n",
    "                                          \"\"\"\n",
    "        \n",
    "        # Step 2 - Construct the prompt for the model using retrieved information and query\n",
    "        prompt = f\"\"\"\n",
    "          You are an HR assistant for our company.Use only following information to answer the query.\n",
    "          If you do not know the answer based on this information then say No - don't make up an answer\n",
    "\n",
    "          RETRIEVED INFORMATION :\n",
    "          {retrieved_info}\n",
    "\n",
    "          USER QUESTION:\n",
    "          {query}\n",
    "            \"\"\"\n",
    "    \n",
    "        # Step 3 - Construct the payload\n",
    "        # Generate a response using the specified model\n",
    "        if 'claude' in model_id.lower():\n",
    "            payload = {\n",
    "               \"anthropic_version\": \"bedrock-2023-05-31\", # Specify the version of the Anthropic model to use\n",
    "               \"max_tokens\": 512, # How many words (max tokens) the AI can respond with (up to 512).\n",
    "               \"temperature\" : 0.5, #How “creative” or random the answers should be (temperature 0.5 means moderately creative).\n",
    "               \"messages\" :[\n",
    "                    {\n",
    "                         \"role\": \"user\",# The role of the user in the conversation\n",
    "                         \"content\": prompt # The actual text of the user message, which includes the retrieved information and the user's question\n",
    "                     \n",
    "                  }\n",
    "                  \n",
    "               ]\n",
    "            }\n",
    "        else:\n",
    "            # Generic format for other models.\n",
    "            payload = {\n",
    "                \"inputText\": prompt,\n",
    "                \"textGenerationConfig\": {\n",
    "                    \"maxTokenCount\": 256,\n",
    "                    \"temperature\": 0.9\n",
    "                }\n",
    "            }\n",
    "        # Step 4 - Call the model   \n",
    "        response = bedrock_runtime.invoke_model(\n",
    "            modelId=model_id,\n",
    "            body=json.dumps(payload), # Convert the payload to JSON format\n",
    "            contentType=\"application/json\", # Specify the content type as JSON\n",
    "            accept=\"application/json\" # Specify the response format as JSON\n",
    "        )\n",
    "        # Step 5 - Parse the response based on the model type.\n",
    "        response_body = json.loads(response['body'].read().decode('utf-8')) # Read and decode the response body\n",
    "        ###       \n",
    "        if 'claude' in model_id.lower():\n",
    "            generated_text = response_body[\"content\"][0][\"text\"]\n",
    "        else:\n",
    "            generated_text = response_body[\"results\"][0][\"outputText\"]\n",
    "        \n",
    "        return generated_text\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"An error occurred while generating the response:{str (e)}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b57b60",
   "metadata": {},
   "source": [
    "#### Step 4:  Test RAG Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2258e853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " User Query:  What is the role of my manager ?\n",
      "\n",
      " Response from RAG Model: \n",
      "No\n"
     ]
    }
   ],
   "source": [
    "# Define a sample knowledge base ID - This would be a real ID in a production scenario\n",
    "sample_kb_id = \"sample hr knowledge base id\"  # Replace with your actual knowledge base ID\n",
    "# Test query\n",
    "# test_query = \"How many PTO days do full-time employees get per year?\"\n",
    "#test_query = \"Is current remote work policy is applicable for full time employees only? What about part time employees?\"\n",
    "test_query = \" What is the role of my manager ?\"\n",
    "# test_query = \"Why all employees are expected to work from office from Monday to Wednesday?\"  # Uncomment to use this query\n",
    "# # Call the function to generate a response\n",
    "response = generate_rag_response(test_query, sample_kb_id)\n",
    "print(\"\\n User Query:\", test_query)\n",
    "print(\"\\n Response from RAG Model:\", response)\n",
    "# --- End  ---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b442c3d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab71349c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question about time off process:\n",
      "\n",
      "You must submit the request at least two weeks in advance via the HR portal.\n",
      "\n",
      "Question about remote work policy (not in our example knowledge base):\n",
      "\n",
      "No\n"
     ]
    }
   ],
   "source": [
    "# Test with a question that should be answerable from our knowledge base\n",
    "test_query_2 = \"What's the process for requesting time off?\"\n",
    "response_2 = generate_rag_response(test_query_2, sample_kb_id)\n",
    "\n",
    "# Test with a question that might not be in our knowledge base\n",
    "test_query_3 = \"What's the company policy on remote work?\"\n",
    "response_3 = generate_rag_response(test_query_3, sample_kb_id)\n",
    "\n",
    "print(\"\\nQuestion about time off process:\")\n",
    "print(response_2)\n",
    "\n",
    "print(\"\\nQuestion about remote work policy (not in our example knowledge base):\")\n",
    "print(response_3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a25581d",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca61b564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket hr-knowledge-base-v02-257269733378 already exists\n"
     ]
    }
   ],
   "source": [
    "# Set up the Knowledge Base Using Vector Database\n",
    "# Step 1 - Create S3 bucket. Create markdown file containing HR Policies and store in AWS s3\n",
    "\n",
    "import boto3\n",
    "\n",
    "# Initialize boto3 S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Generate a unique bucket name using your account ID\n",
    "account_id = boto3.client('sts').get_caller_identity()['Account']\n",
    "bucket_name = f\"hr-knowledge-base-v02-{account_id}\"\n",
    "\n",
    "# Check if the bucket already exists\n",
    "def bucket_exists(bucket_name):\n",
    "    response = s3.list_buckets()\n",
    "    buckets = [bucket['Name'] for bucket in response['Buckets']]\n",
    "    return bucket_name in buckets\n",
    "\n",
    "# Create the bucket if it doesn't exist\n",
    "if not bucket_exists(bucket_name):\n",
    "    try:\n",
    "        s3.create_bucket(Bucket=bucket_name)\n",
    "        print(f\"Created bucket: {bucket_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating bucket: {str(e)}\")\n",
    "else:\n",
    "    print(f\"Bucket {bucket_name} already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "766051a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample HR policy markdown file\n",
    "hr_policy_v02 = \"\"\" # Human Resources (HR) Policy\n",
    "Preamble\n",
    "The Human Resources (HR) Policy of [Organization Name] is designed to define the principles, processes, and standards that govern the management of human capital in the organization. This policy serves as a comprehensive guide to ensure fair, consistent, and legally compliant practices that promote a productive, respectful, and inclusive workplace.\n",
    "The organization recognizes that employees are its most valuable asset and is committed to fostering a work environment that attracts, develops, and retains top talent while ensuring alignment with the organization’s mission, values, and strategic objectives.\n",
    "\n",
    "Policy Point 1: Recruitment & Selection\n",
    "1.1 Objective\n",
    "To ensure a transparent, merit-based, and non-discriminatory recruitment process that attracts qualified candidates who align with organizational values and role requirements.\n",
    "\n",
    "1.2 Scope\n",
    "Applies to all permanent, contractual, part-time, and temporary hiring.\n",
    "\n",
    "1.3 Guidelines\n",
    "Workforce Planning: HR will conduct annual workforce planning with department heads to identify staffing needs.\n",
    "Job Descriptions: Each role must have an up-to-date job description approved by HR.\n",
    "Advertising Vacancies: Positions shall be advertised internally and externally to ensure equal opportunity.\n",
    "Selection Process: Structured interviews, competency-based assessments, and background checks will be conducted.\n",
    "Equal Opportunity: All recruitment will comply with anti-discrimination laws, ensuring no bias based on age, gender, race, religion, or disability.\n",
    "Offer Letters: Shall be issued only after approvals from HR and relevant hiring managers.\n",
    "\n",
    "Policy Point 2: Onboarding & Induction\n",
    "2.1 Objective\n",
    "To integrate new hires effectively into the organization's culture, processes, and performance expectations.\n",
    "\n",
    "2.2 Process\n",
    "Pre-Onboarding: HR will provide offer confirmation, joining instructions, and required documentation list.\n",
    "Orientation Program: Includes introduction to company history, values, organizational structure, key policies, IT systems, and safety protocols.\n",
    "Probationary Period: All new employees will undergo a probationary period (3-6 months) with performance reviews at 30, 60, and 90 days.\n",
    "Buddy System: New hires will be assigned a workplace buddy for their first month to aid in cultural integration.\n",
    "\n",
    "Policy Point 3: Employee Classification & Contracts\n",
    "3.1 Classification Categories\n",
    "Permanent Employees\n",
    "Fixed-Term Contract Employees\n",
    "Part-Time Employees\n",
    "Interns & Trainees\n",
    "\n",
    "3.2 Employment Contracts\n",
    "Must clearly state role, remuneration, benefits, working hours, probation period, and termination clauses.\n",
    "Contracts must comply with national labor laws.\n",
    "\n",
    "Policy Point 4: Compensation & Benefits\n",
    "4.1 Salary Structure\n",
    "Based on job grade, market benchmarking, and internal equity.\n",
    "Reviewed annually through performance appraisal and market adjustment.\n",
    "\n",
    "4.2 Benefits\n",
    "Health insurance coverage for employee and eligible dependents.\n",
    "Retirement benefits as per statutory requirements.\n",
    "Paid leave entitlements (annual, sick, maternity/paternity, compassionate).\n",
    "Employee Assistance Program (EAP) for mental well-being.\n",
    "\n",
    "4.3 Payroll\n",
    "Salaries will be processed monthly, with payslips provided electronically.\n",
    "Statutory deductions (tax, social security, provident fund) will be applied as per law.\n",
    "\n",
    "Policy Point 5: Working Hours, Attendance & Leave\n",
    "5.1 Working Hours\n",
    "Standard workweek: [e.g., 40 hours, Monday-Friday, 9 AM-6 PM].\n",
    "Flexible work arrangements subject to manager approval.\n",
    "\n",
    "5.2 Attendance\n",
    "Electronic attendance system; employees must clock in/out.\n",
    "Uninformed absence beyond 3 days may result in disciplinary action.\n",
    "\n",
    "5.3 Leave Policy\n",
    "Annual Leave: [X] days per year.\n",
    "Sick Leave: [X] days with medical certificate for absences exceeding 2 days.\n",
    "Maternity/Paternity Leave: As per statutory law.\n",
    "Unpaid Leave: Subject to management approval.\n",
    "\n",
    "Policy Point 6: Performance Management\n",
    "6.1 Objective\n",
    "To establish a fair and consistent performance evaluation process that aligns individual goals with organizational strategy.\n",
    "\n",
    "6.2 Process\n",
    "Goal Setting: Annual goals agreed upon between employee and manager.\n",
    "Mid-Year Review: Formal review of progress.\n",
    "Annual Appraisal: Based on KPIs, competencies, and behavioral attributes.\n",
    "Performance Improvement Plans (PIP): For underperforming employees with clear timelines and support mechanisms.\n",
    "\n",
    "Policy Point 7: Learning & Development\n",
    "7.1 Commitment\n",
    "The organization will invest in employee development through structured training and learning opportunities.\n",
    "\n",
    "7.2 Framework\n",
    "\n",
    "Training Needs Analysis (TNA) conducted annually.\n",
    "Internal & External Training programs provided.\n",
    "Career Development Plans for high-potential employees.\n",
    "Tuition Assistance for approved courses.\n",
    "\n",
    "Policy Point 8: Employee Conduct & Discipline\n",
    "8.1 Code of Conduct\n",
    "Employees must act with integrity, respect, and professionalism.\n",
    "\n",
    "8.2 Disciplinary Process\n",
    "Verbal Warning → Written Warning → Final Warning → Termination (depending on severity).\n",
    "Immediate dismissal for gross misconduct (e.g., fraud, violence, harassment).\n",
    "\n",
    "8.3 Workplace Harassment Policy\n",
    "Zero tolerance for harassment, bullying, or discrimination. Complaints will be investigated confidentially.\n",
    "\n",
    "Policy Point 9: Health, Safety & Welfare\n",
    "9.1 Health & Safety Commitment\n",
    "Compliance with Occupational Health & Safety (OHS) laws.\n",
    "Risk assessments conducted annually.\n",
    "First aid facilities and emergency procedures in place.\n",
    "\n",
    "9.2 Wellness Programs\n",
    "Annual health check-ups.\n",
    "Fitness subsidies.\n",
    "Mental health awareness campaigns.\n",
    "\n",
    "Policy Point 10: Exit & Termination\n",
    "10.1 Voluntary Resignation\n",
    "Notice period: [e.g., 1 month].\n",
    "Exit interview to gather feedback.\n",
    "\n",
    "10.2 Termination by Employer\n",
    "Based on performance, redundancy, or misconduct.\n",
    "Notice or payment in lieu of notice as per contract.\n",
    "\n",
    "10.3 Final Settlement\n",
    "Clearance of company property.\n",
    "Settlement of outstanding salary, benefits, and leave encashment.\n",
    "\n",
    "Implementation & Review\n",
    "HR will review the policy annually.\n",
    "Changes require approval from the HR Director and CEO.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3ef8606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR policy file uploaded to S3 bucket hr-knowledge-base-v02-257269733378 successfully.\n"
     ]
    }
   ],
   "source": [
    "## Save the HR policy content to a markdown file in S3\n",
    "with open('hr_policy_v02.md', 'w', encoding='utf-8') as file:\n",
    "    file.write(hr_policy_v02)\n",
    "# Upload the markdown file to the S3 bucket\n",
    "try:    \n",
    "    s3.upload_file('hr_policy_v02.md', bucket_name, 'hr_policy_v02.md')\n",
    "    print(f\"HR policy file uploaded to S3 bucket {bucket_name} successfully.\")  \n",
    "except Exception as e:\n",
    "    print(f\"Error uploading HR policy file to S3: {str(e)}\")    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1212d399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "# model_id = \"amazon.titan-text-express-v1\"  # Default\n",
    "# model_id = \"amazon.titan-embed-image-v1\"  # Default\n",
    "model_id = \"amazon.titan-text-express-v1\"\n",
    "# model_id = \"amazon.titan-embed-text-v1\"\n",
    "# model_id = \"amazon.titan-text-premier-v1:0\"  # Default\n",
    "# model_id = \"anthropic.claude-v2:1\"  # Default\n",
    "region = \"us-east-1\"  # Change this to your AWS region\n",
    "\n",
    "def query_hr_knowledge_base(user_query, knowledge_base_id, model_id=model_id, region=region):\n",
    "    \"\"\"\n",
    "    Query HR Knowledge Base and generate a response using a RAG Model.\n",
    "    Args:\n",
    "        user_query (str): The user's question.\n",
    "        knowledge_base_id (str): ID of the knowledge base to query.\n",
    "        model_id (str): The model ID to use.\n",
    "        region (str): AWS region where Bedrock is deployed.\n",
    "    \"\"\"\n",
    "    bedrock_runtime = boto3.client(\"bedrock-runtime\", region_name=region)\n",
    "    bedrock_agent_runtime = boto3.client('bedrock-agent-runtime', region_name=region)\n",
    "\n",
    "    try:\n",
    "        retrieve_response = bedrock_agent_runtime.retrieve(\n",
    "            knowledgeBaseId=knowledge_base_id,\n",
    "            retrievalQuery={'text': user_query},\n",
    "            retrievalConfiguration={\n",
    "                'vectorSearchConfiguration': {\n",
    "                    'numberOfResults': 5  # Top 5 relevant results\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Extract retrieved information\n",
    "        retrieved_passages = []\n",
    "        for result in retrieve_response.get('retrievedResults', []):\n",
    "            content = result.get('content', {}).get('text', '')\n",
    "            source = \"Unknown source\"\n",
    "            location = result.get('location', {})\n",
    "\n",
    "            if location:\n",
    "                if 's3location' in location:\n",
    "                    source = location.get('s3location', {}).get('uri', source)\n",
    "                elif 'type' in location:\n",
    "                    source = location.get('type', source)\n",
    "\n",
    "            score = result.get('score', 0)\n",
    "            retrieved_passages.append({\n",
    "                'content': content,\n",
    "                'source': source,\n",
    "                'relevance_score': score\n",
    "            })\n",
    "\n",
    "        # Prepare context\n",
    "        context = \"\\n\\n\".join([f\"Passage: {p['content']}\" for p in retrieved_passages])\n",
    "        if not context:\n",
    "            context = \"No relevant information found in the knowledge base.\"\n",
    "\n",
    "        # Construct prompt\n",
    "        prompt = f\"\"\"\n",
    "        You are HR Manager who is helping employees to easily understand policies.  Use only the following information to answer the query.\n",
    "        If you do not know the answer based on this information then say:\n",
    "        'No I do not have definitive answer for this as of now' — don't make up an answer.\n",
    "\n",
    "        Context:\n",
    "        {context}\n",
    "\n",
    "        Question: {user_query}\n",
    "\n",
    "        Answer:\n",
    "        \"\"\"\n",
    "\n",
    "        # Select payload based on model type\n",
    "        if \"anthropic\" in model_id.lower():\n",
    "            print(\"Inside Anthropic Model\")\n",
    "            payload = {\n",
    "                \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "                \"max_tokens\": 512,\n",
    "                \"temperature\": 0.5,\n",
    "                \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
    "            }\n",
    "        # elif \"amazon.titan\" in model_id.lower():\n",
    "        #     print(\"Inside Amazon Titan Model\")\n",
    "        #     payload = {\n",
    "        #         \"inputText\": prompt,\n",
    "        #         \"textGenerationConfig\": {\n",
    "        #             \"maxTokenCount\": 512,\n",
    "        #             \"temperature\": 0.6,\n",
    "        #             \"topP\": 0.9\n",
    "        #         }\n",
    "        #     }\n",
    "        elif \"amazon.titan\" in model_id.lower():\n",
    "            print(\"Inside Amazon Titan Model\")\n",
    "\n",
    "            if \"embed\" in model_id.lower():\n",
    "        # Embedding model payload (no textGenerationConfig)\n",
    "                 payload = {\n",
    "                \"inputText\": prompt\n",
    "                }\n",
    "            else:\n",
    "             # Text generation model payload\n",
    "                 payload = {\n",
    "                   \"inputText\": prompt,\n",
    "                   \"textGenerationConfig\": {\n",
    "                   \"maxTokenCount\": 800,\n",
    "                   \"temperature\": 0.8,\n",
    "                   \"topP\": 0.7\n",
    "            }\n",
    "        }\n",
    "    #----###\n",
    "        elif \"meta.llama\" in model_id.lower():\n",
    "            print(\"Inside Meta Llama Model\")\n",
    "            payload = {\n",
    "                \"inputText\": prompt,\n",
    "                \"textGenerationConfig\": {\n",
    "                    \"maxTokenCount\": 512,\n",
    "                    \"temperature\": 0.7,\n",
    "                    \"topP\": 0.9\n",
    "                }\n",
    "            }\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model ID: {model_id}. Please use a supported model ID for RAG workflows.\")\n",
    "\n",
    "        # Call the model\n",
    "        invoke_response = bedrock_runtime.invoke_model(\n",
    "            modelId=model_id,\n",
    "            body=json.dumps(payload),\n",
    "            contentType=\"application/json\",\n",
    "            accept=\"application/json\"\n",
    "        )\n",
    "\n",
    "        # Parse the response\n",
    "        response_body = json.loads(invoke_response['body'].read().decode('utf-8'))\n",
    "\n",
    "        if \"anthropic\" in model_id.lower():\n",
    "            generated_answer = response_body.get('content', [{}])[0].get(\"text\", \"\")\n",
    "        elif \"amazon.titan\" in model_id.lower():\n",
    "            generated_answer = response_body.get('results', [{}])[0].get(\"outputText\", '')\n",
    "        elif \"meta.llama\" in model_id.lower():\n",
    "            generated_answer = response_body.get('generation', '')\n",
    "        else:\n",
    "            generated_answer = \"Error: Could not parse response from the model.\"\n",
    "\n",
    "        # Final return\n",
    "        return {\n",
    "            \"query\": user_query,\n",
    "            \"retrieved_passages\": retrieved_passages,\n",
    "            \"generated_answer\": generated_answer,\n",
    "            \"model_used\": model_id\n",
    "        }\n",
    "    # Titan Embeddings G1 - Textv1.2\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"error\": str(e),\n",
    "            \"query\": user_query,\n",
    "            \"knowledge_base_id\": knowledge_base_id,\n",
    "            \"retrieved_passages\": [],\n",
    "            \"model_id\": model_id\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "19a268cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Id is : amazon.titan-text-express-v1\n",
      "Inside Amazon Titan Model\n",
      "\n",
      "============================================================\n",
      "Query: On what basis employee's compensation & benefits are revised or determined ?\n",
      "\n",
      "No retrieved information found.\n",
      "\n",
      "Generated Answer:\n",
      "  It is determined by job evaluation.\n"
     ]
    }
   ],
   "source": [
    "##Retrievel Example\n",
    "# Define a sample knowledge base ID - This would be a real ID in a production scenario\n",
    "sample_kb_id = \"GIVL72SHRJ\"  # Replace with your actual knowledge base ID\n",
    "#sample_kb_id = \"ZHJZPXTKEV\"\n",
    "# sample_kb_id = \"KU4HIUJJNS\"  \n",
    "print(f\"Model Id is : {model_id}\")\n",
    "\n",
    "# Test with a question that should be answerable from our knowledge base\n",
    "# query = \"What type of wellness programs are run by company ?\"\n",
    "# query = 'Who conducts annual workforce planning ?'\n",
    "# query = \"Who can avail Remote working benefit?\"\n",
    "# query = \"When medical certificate is required ?\"\n",
    "query = \"On what basis employee's compensation & benefits are revised or determined ?\"\n",
    "# query = \"What is the health and safety policy of the company.\"\n",
    "#query = \"How frequently salary is paid ?\"  # Uncomment to use this query\n",
    "result = query_hr_knowledge_base(query, sample_kb_id, model_id)\n",
    "if result is not None:\n",
    "    print(\"\\n\" + \"==\"*30)\n",
    "    print(f\"Query: {result.get('query', '')}\")\n",
    "    if result.get('retrieved_passages'):\n",
    "        print(f\"\\nRetrieved Information:\\n{result['retrieved_passages'][0]['content']}\")\n",
    "    else:\n",
    "        print(\"\\nNo retrieved information found.\")\n",
    "    if 'generated_answer' in result:\n",
    "        print(f\"\\nGenerated Answer:\\n {result['generated_answer']}\")\n",
    "    elif 'error' in result:\n",
    "        print(f\"\\nError:\\n {result['error']}\")\n",
    "    else:\n",
    "        print(\"\\nNo answer generated.\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AWSBedrock",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
