{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d01f727",
   "metadata": {},
   "source": [
    "#### Step 1 : Import Required Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3bcaf5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import required Libs\n",
    "import boto3\n",
    "import json\n",
    "from botocore.exceptions import BotoCoreError, ClientError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255ad0f9",
   "metadata": {},
   "source": [
    "#### Step 2 : Set AWS Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3de5e4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Environment is setup successfully\n"
     ]
    }
   ],
   "source": [
    "## Set AWS Region\n",
    "try:\n",
    "    # Set AWS Region\n",
    "    region = \"us-east-1\"  # Note the correct region code \"us-east-1\"\n",
    "    \n",
    "    # The Bedrock runtime must be initialized with your AWS credentials/profile and region to authenticate you \n",
    "    # and direct requests to the right foundation models or agent.\n",
    "    bedrock_runtime = boto3.client(\"bedrock-runtime\", region_name=region)\n",
    "    s3 = boto3.client(\"s3\", region_name=region)\n",
    "    \n",
    "    print(\"Project Environment is setup successfully\")\n",
    "    \n",
    "except (BotoCoreError, ClientError) as error:\n",
    "    print(f\"An error occurred while setting up AWS clients: {error}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5d78ad",
   "metadata": {},
   "source": [
    "#### Step-3 : Setup RAG Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a3fe83",
   "metadata": {},
   "source": [
    "###### 1. Take user query\n",
    "###### 2. Retrieve relevant information from our knowledge base\n",
    "###### 3. Generate a response using a foundation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6323fcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##--------------------------------------------------------------------------------------------------------------------------------------------- \n",
    "## 1] RAG Model - Amazon Titan text foundation model available via Amazon Bedrock.\n",
    "##  This model is a large language model (LLM) optimized for a wide range of advanced, general-purpose language\n",
    "##  tasks such as open-ended text generation, conversational chat, and also supports Retrieval Augmented Generation (RAG) workflows.\n",
    "##  ---\n",
    "## 2] knowledge_base_id identifies the knowledge base to query.This is a unique identifier (typically a string or an Amazon Resource Name, ARN)\n",
    "##  that specifies which knowledge base your application or model should access during information retrieval.\n",
    "##  In the context of Amazon Bedrock: A knowledge base is a structured repository of information—often created by ingesting private documents,\n",
    "##  databases, or other content. Amazon Bedrock uses these knowledge bases to support Retrieval-Augmented Generation (RAG) workflows.\n",
    "##  The knowledge_base_id is the unique ID assigned to a specific knowledge base within Amazon Bedrock. When issuing a query,\n",
    "##  this ID tells Bedrock which knowledge base to search for relevant information.\n",
    "##---------------------------------------------------------------------------------------------------------------------------------------------\n",
    "##\n",
    "model_id = \"amazon.titan-text-express-v1\"\n",
    "def generate_rag_response(query,knowledge_base_id, model_id = model_id):\n",
    "    \"\"\" Generate Response using RAG Approach\n",
    "        Args :\n",
    "         1] query (str) : The user's question\n",
    "         2] knowledge_base_id (str) : ID of the knowledge base to query\n",
    "    \"\"\"\n",
    "    try: \n",
    "        \"\"\" Step-1 : Retrieve information from the knowledge base\n",
    "        # Note : In a full implemenation, we would call the Bedrock Knowledge Base API here\n",
    "        # For this example, we will simulate the retrieval with a placeholder\n",
    "        # bedrock_agent_runtime = boto3.client('bedrock-agent-runtime', region_name = region)\n",
    "        # kb_response = bedrock_agent_runtime.retrieve(\n",
    "           knowledgeBaseId=knowledge_base_id,\n",
    "           retrivalQuery ={'text' : query},\n",
    "           numberOfResults = 3)\n",
    "       \"\"\"\n",
    "       ## For simplified example:\n",
    "        retrieved_info =\"\"\" Employee Handbook Section 3.2 : Pait Time Off\n",
    "         All Employees accrue PTO at a rate of 1.5 days per month (18 days per year).\n",
    "         PTO requests must be submitted at least two weeks in advance through the HR portal\n",
    "         Unused PTO can be carried over to the following year, up to a maximum of 5 days\n",
    "         For further queries on PTO, please contact hr@example.com\n",
    "\n",
    "         Remote work policy for full time employees only - Full time employees are eligible to work remotely \n",
    "         up to 2 days per week and max of 10 days per month under unavoidable circumstances only when manager \n",
    "         has approved additional remote work days. Under normal circumstances, full time employees are expected to work from office for 3 days a week.\n",
    "         For consitency, co-ordination and efficiency purpose, all employees are expected to work from\n",
    "         office from Monday to Wednesday.\n",
    "                                          \"\"\"\n",
    "        \n",
    "        # Step 2 - Construct the prompt for the model using retrieved information and query\n",
    "        prompt = f\"\"\"\n",
    "          You are an HR assistant for our company.Use only following information to answer the query.\n",
    "          If you do not know the answer based on this information then say No - don't make up an answer\n",
    "\n",
    "          RETRIEVED INFORMATION :\n",
    "          {retrieved_info}\n",
    "\n",
    "          USER QUESTION:\n",
    "          {query}\n",
    "            \"\"\"\n",
    "    \n",
    "        # Step 3 - Construct the payload\n",
    "        # Generate a response using the specified model\n",
    "        if 'claude' in model_id.lower():\n",
    "            payload = {\n",
    "               \"anthropic_version\": \"bedrock-2023-05-31\", # Specify the version of the Anthropic model to use\n",
    "               \"max_tokens\": 512, # How many words (max tokens) the AI can respond with (up to 512).\n",
    "               \"temperature\" : 0.5, #How “creative” or random the answers should be (temperature 0.5 means moderately creative).\n",
    "               \"messages\" :[\n",
    "                    {\n",
    "                         \"role\": \"user\",# The role of the user in the conversation\n",
    "                         \"content\": prompt # The actual text of the user message, which includes the retrieved information and the user's question\n",
    "                     \n",
    "                  }\n",
    "                  \n",
    "               ]\n",
    "            }\n",
    "        else:\n",
    "            # Generic format for other models.\n",
    "            payload = {\n",
    "                \"inputText\": prompt,\n",
    "                \"textGenerationConfig\": {\n",
    "                    \"maxTokenCount\": 256,\n",
    "                    \"temperature\": 0.9\n",
    "                }\n",
    "            }\n",
    "        # Step 4 - Call the model   \n",
    "        response = bedrock_runtime.invoke_model(\n",
    "            modelId=model_id,\n",
    "            body=json.dumps(payload), # Convert the payload to JSON format\n",
    "            contentType=\"application/json\", # Specify the content type as JSON\n",
    "            accept=\"application/json\" # Specify the response format as JSON\n",
    "        )\n",
    "        # Step 5 - Parse the response based on the model type.\n",
    "        response_body = json.loads(response['body'].read().decode('utf-8')) # Read and decode the response body\n",
    "        ###       \n",
    "        if 'claude' in model_id.lower():\n",
    "            generated_text = response_body[\"content\"][0][\"text\"]\n",
    "        else:\n",
    "            generated_text = response_body[\"results\"][0][\"outputText\"]\n",
    "        \n",
    "        return generated_text\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"An error occurred while generating the response:{str (e)}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b57b60",
   "metadata": {},
   "source": [
    "#### Step 4:  Test RAG Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2258e853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " User Query:  What is the role of my manager ?\n",
      "\n",
      " Response from RAG Model: \n",
      "The manager is expected to approve additional remote work days when circumstances arise, and to coordinate and ensure efficiency in the workplace\n"
     ]
    }
   ],
   "source": [
    "# Define a sample knowledge base ID - This would be a real ID in a production scenario\n",
    "sample_kb_id = \"sample hr knowledge base id\"  # Replace with your actual knowledge base ID\n",
    "# Test query\n",
    "# test_query = \"How many PTO days do full-time employees get per year?\"\n",
    "#test_query = \"Is current remote work policy is applicable for full time employees only? What about part time employees?\"\n",
    "test_query = \" What is the role of my manager ?\"\n",
    "# test_query = \"Why all employees are expected to work from office from Monday to Wednesday?\"  # Uncomment to use this query\n",
    "# # Call the function to generate a response\n",
    "response = generate_rag_response(test_query, sample_kb_id)\n",
    "print(\"\\n User Query:\", test_query)\n",
    "print(\"\\n Response from RAG Model:\", response)\n",
    "# --- End  ---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b442c3d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab71349c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question about time off process:\n",
      "\n",
      "No.\n",
      "\n",
      "Question about remote work policy (not in our example knowledge base):\n",
      "\n",
      "The company policy on remote work is that full time employees are eligible to work remotely up to 2 days per week and max of 10 days per month under unavoidable circumstances only when manager has approved additional remote work days.\n"
     ]
    }
   ],
   "source": [
    "# Test with a question that should be answerable from our knowledge base\n",
    "test_query_2 = \"What's the process for requesting time off?\"\n",
    "response_2 = generate_rag_response(test_query_2, sample_kb_id)\n",
    "\n",
    "# Test with a question that might not be in our knowledge base\n",
    "test_query_3 = \"What's the company policy on remote work?\"\n",
    "response_3 = generate_rag_response(test_query_3, sample_kb_id)\n",
    "\n",
    "print(\"\\nQuestion about time off process:\")\n",
    "print(response_2)\n",
    "\n",
    "print(\"\\nQuestion about remote work policy (not in our example knowledge base):\")\n",
    "print(response_3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a25581d",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca61b564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket hr-knowledge-base-v02-257269733378 already exists\n"
     ]
    }
   ],
   "source": [
    "# Set up the Knowledge Base Using Vector Database\n",
    "# Step 1 - Create S3 bucket. Create markdown file containing HR Policies and store in AWS s3\n",
    "\n",
    "import boto3\n",
    "\n",
    "# Initialize boto3 S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Generate a unique bucket name using your account ID\n",
    "account_id = boto3.client('sts').get_caller_identity()['Account']\n",
    "bucket_name = f\"hr-knowledge-base-v02-{account_id}\"\n",
    "\n",
    "# Check if the bucket already exists\n",
    "def bucket_exists(bucket_name):\n",
    "    response = s3.list_buckets()\n",
    "    buckets = [bucket['Name'] for bucket in response['Buckets']]\n",
    "    return bucket_name in buckets\n",
    "\n",
    "# Create the bucket if it doesn't exist\n",
    "if not bucket_exists(bucket_name):\n",
    "    try:\n",
    "        s3.create_bucket(Bucket=bucket_name)\n",
    "        print(f\"Created bucket: {bucket_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating bucket: {str(e)}\")\n",
    "else:\n",
    "    print(f\"Bucket {bucket_name} already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "766051a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample HR policy markdown file\n",
    "hr_policy_v03 = \"\"\" ABCSoftware - Human Resources (HR) Policy-V1.3\n",
    "Preamble\n",
    "The Human Resources (HR) Policy of [Organization Name] defines the guiding principles and procedures for effective management of our people. This policy ensures fair, consistent, and legally compliant practices to cultivate a productive, respectful, and welcoming workplace. We recognize our employees as our greatest asset and are committed to creating an environment that attracts, develops, and retains talent while supporting our mission, values, and strategic objectives.\n",
    "\n",
    "1. Recruitment and Selection\n",
    "The organization is committed to a transparent, merit-based recruitment process that welcomes qualified candidates aligned with our values and job requirements. This policy applies to all forms of employment, whether permanent, contractual, part-time, or temporary. HR will work with department heads annually to assess workforce needs and maintain current job descriptions. Vacancies are advertised both internally and externally to promote equal opportunity, and the selection process includes structured interviews, competency assessments, and background checks. All recruitment shall comply with non-discrimination laws to avoid any bias regarding age, gender, race, religion, or disability. Offer letters are provided only after all necessary approvals.\n",
    "\n",
    "2. Onboarding and Induction\n",
    "We strive to integrate new hires smoothly into our culture and processes. Upon joining, HR provides offer confirmation, joining instructions, and a list of required documents. New employees participate in an orientation program introducing our history, values, structure, key policies, IT systems, and safety procedures. All new employees serve a probationary period of three to six months, with formal reviews at 30, 60, and 90 days. A workplace buddy is assigned for the first month to assist in acclimatization.\n",
    "\n",
    "3. Employee Classification and Contracts\n",
    "Employees are classified into permanent, fixed-term contract, part-time, and internships or traineeships. Each employment contract clearly states the role, pay, benefits, working hours, probation period, and termination clauses, in compliance with applicable labor laws.\n",
    "\n",
    "4. Compensation and Benefits\n",
    "Salaries are defined by job grade, market benchmarks, and internal equity and are reviewed annually. Employees receive health insurance for themselves and eligible dependents, retirement benefits according to statutory requirements, paid leave entitlements (annual, sick, maternity/paternity, and compassionate), and access to an Employee Assistance Program for mental wellbeing. Salaries are processed monthly with electronic payslips, and statutory deductions are made as per legal requirements.\n",
    "\n",
    "5. Working Hours, Attendance, and Leave\n",
    "The standard workweek is [e.g., 40 hours, Monday through Friday, 9 AM to 6 PM], with flexible work arrangements available with managerial approval. Attendance is tracked electronically; staff must clock in and out. Uninformed absences beyond three days may lead to disciplinary action. Leave entitlements include a set number of annual and sick days, with additional leave for maternity/paternity in accordance with the law. Unpaid leave is possible with approval.\n",
    "\n",
    "6. Performance Management\n",
    "We aim to fairly evaluate performance, aligning individual goals with the organization's objectives. Annual goals are set collaboratively and formally reviewed mid-year, with an annual appraisal focusing on key performance indicators, competencies, and behaviors. Performance improvement plans are available for underperforming staff, with defined timelines and support.\n",
    "\n",
    "7. Learning and Development\n",
    "The organization invests in employee growth through ongoing training and development opportunities. Training needs are assessed each year, and both internal and external programs are provided. High-potential employees benefit from career development plans, and tuition assistance is available for approved studies.\n",
    "\n",
    "8. Employee Conduct and Discipline\n",
    "Employees must demonstrate integrity, respect, and professionalism at all times. Disciplinary procedures follow a progressive process from verbal to written to final warning, then termination as appropriate, with immediate dismissal possible for gross misconduct such as fraud, violence, or harassment. There is zero tolerance for harassment, bullying, or discrimination; complaints will be investigated confidentially.\n",
    "\n",
    "9. Health, Safety, and Welfare\n",
    "[Organization Name] complies with all Occupational Health and Safety laws. Annual risk assessments are conducted and first aid facilities and emergency procedures are maintained. Employees are encouraged to participate in wellness programs, including annual health check-ups, fitness subsidies, and mental health initiatives.\n",
    "\n",
    "10. Exit and Termination\n",
    "When an employee voluntarily resigns, the required notice period (typically one month) must be served, and an exit interview is conducted. Termination by the employer may occur due to performance issues, redundancy, or misconduct; in these cases, notice or payment in lieu is provided per contract. Final settlements cover the return of company property and payment of remaining salary, benefits, and any applicable leave encashment.\n",
    "\n",
    "Implementation and Review\n",
    "This HR policy will be reviewed annually by the HR department. Any changes must be approved by both the HR Director and the CEO to ensure ongoing relevance and legal compliance\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e3ef8606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR policy file uploaded to S3 bucket hr-knowledge-base-v02-257269733378 successfully.\n"
     ]
    }
   ],
   "source": [
    "## Save the HR policy content to a markdown file in S3\n",
    "with open('hr_policy_v03.md', 'w', encoding='utf-8') as file:\n",
    "    file.write(hr_policy_v03)\n",
    "# Upload the markdown file to the S3 bucket\n",
    "try:    \n",
    "    s3.upload_file('hr_policy_v03.md', bucket_name, 'hr_policy_v03.md')\n",
    "    print(f\"HR policy file uploaded to S3 bucket {bucket_name} successfully.\")  \n",
    "except Exception as e:\n",
    "    print(f\"Error uploading HR policy file to S3: {str(e)}\")    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1212d399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "# model_id = \"amazon.titan-text-express-v1\"  # Default\n",
    "# model_id = \"amazon.titan-embed-image-v1\"  # Default\n",
    "#model_id = \"amazon.titan-text-express-v1\"\n",
    "model_id = \"amazon.titan-embed-text-v1\"\n",
    "# model_id = \"amazon.titan-text-premier-v1:0\"  # Default\n",
    "# model_id = \"anthropic.claude-v2:1\"  # Default\n",
    "region = \"us-east-1\"  # Change this to your AWS region\n",
    "\n",
    "def query_hr_knowledge_base(user_query, knowledge_base_id, model_id=model_id, region=region):\n",
    "    \"\"\"\n",
    "    Query HR Knowledge Base and generate a response using a RAG Model.\n",
    "    Args:\n",
    "        user_query (str): The user's question.\n",
    "        knowledge_base_id (str): ID of the knowledge base to query.\n",
    "        model_id (str): The model ID to use.\n",
    "        region (str): AWS region where Bedrock is deployed.\n",
    "    \"\"\"\n",
    "    # bedrock-runtime client: For basic model invocation and runtime interactions with foundation models on Bedrock.\n",
    "    # bedrock-agent-runtime client: For advanced agent-driven interactions, supporting knowledge bases, \n",
    "    # session context, and retrieval-augmented generation workflows.\n",
    "    bedrock_runtime = boto3.client(\"bedrock-runtime\", region_name=region)\n",
    "    bedrock_agent_runtime = boto3.client('bedrock-agent-runtime', region_name=region)\n",
    "\n",
    "    try:\n",
    "        retrieve_response = bedrock_agent_runtime.retrieve(\n",
    "            knowledgeBaseId=knowledge_base_id,\n",
    "            retrievalQuery={'text': user_query},\n",
    "            retrievalConfiguration={\n",
    "                'vectorSearchConfiguration': {\n",
    "                    'numberOfResults': 5  # Top 5 relevant results\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Extract retrieved information\n",
    "        retrieved_passages = []\n",
    "        for result in retrieve_response.get('retrievedResults', []):\n",
    "            content = result.get('content', {}).get('text', '')\n",
    "            source = \"Unknown source\"\n",
    "            location = result.get('location', {})\n",
    "\n",
    "            if location:\n",
    "                if 's3location' in location:\n",
    "                    source = location.get('s3location', {}).get('uri', source)\n",
    "                elif 'type' in location:\n",
    "                    source = location.get('type', source)\n",
    "\n",
    "            score = result.get('score', 0)\n",
    "            retrieved_passages.append({\n",
    "                'content': content,\n",
    "                'source': source,\n",
    "                'relevance_score': score\n",
    "            })\n",
    "\n",
    "        # Prepare context\n",
    "        context = \"\\n\\n\".join([f\"Passage: {p['content']}\" for p in retrieved_passages])\n",
    "        if not context:\n",
    "            context = \"No relevant information found in the knowledge base.\"\n",
    "\n",
    "        # Construct prompt\n",
    "        prompt = f\"\"\"\n",
    "        You are HR Manager who is helping employees to easily understand policies.  Use only the following information to answer the query.\n",
    "        If you do not know the answer based on this information then say:\n",
    "        'No I do not have definitive answer for this as of now' — don't make up an answer.\n",
    "\n",
    "        Context:\n",
    "        {context}\n",
    "\n",
    "        Question: {user_query}\n",
    "\n",
    "        Answer:\n",
    "        \"\"\"\n",
    "\n",
    "        # Select payload based on model type\n",
    "        if \"anthropic\" in model_id.lower():\n",
    "            print(\"Inside Anthropic Model\")\n",
    "            payload = {\n",
    "                \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "                \"max_tokens\": 512,\n",
    "                \"temperature\": 0.5,\n",
    "                \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
    "            }\n",
    "        # elif \"amazon.titan\" in model_id.lower():\n",
    "        #     print(\"Inside Amazon Titan Model\")\n",
    "        #     payload = {\n",
    "        #         \"inputText\": prompt,\n",
    "        #         \"textGenerationConfig\": {\n",
    "        #             \"maxTokenCount\": 512,\n",
    "        #             \"temperature\": 0.6,\n",
    "        #             \"topP\": 0.9\n",
    "        #         }\n",
    "        #     }\n",
    "        elif \"amazon.titan\" in model_id.lower():\n",
    "            print(\"Inside Amazon Titan Model\")\n",
    "\n",
    "            if \"embed\" in model_id.lower():\n",
    "        # Embedding model payload (no textGenerationConfig)\n",
    "                 payload = {\n",
    "                \"inputText\": prompt\n",
    "                }\n",
    "            else:\n",
    "             # Text generation model payload\n",
    "                 payload = {\n",
    "                   \"inputText\": prompt,\n",
    "                   \"textGenerationConfig\": {\n",
    "                   \"maxTokenCount\": 1000,\n",
    "                   \"temperature\": 0.9,\n",
    "                   \"topP\": 0.7\n",
    "            }\n",
    "        }\n",
    "    #----###\n",
    "        elif \"meta.llama\" in model_id.lower():\n",
    "            print(\"Inside Meta Llama Model\")\n",
    "            payload = {\n",
    "                \"inputText\": prompt,\n",
    "                \"textGenerationConfig\": {\n",
    "                    \"maxTokenCount\": 512,\n",
    "                    \"temperature\": 0.7,\n",
    "                    \"topP\": 0.9\n",
    "                }\n",
    "            }\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model ID: {model_id}. Please use a supported model ID for RAG workflows.\")\n",
    "\n",
    "        # Call the model\n",
    "        invoke_response = bedrock_runtime.invoke_model(\n",
    "            modelId=model_id,\n",
    "            body=json.dumps(payload),\n",
    "            contentType=\"application/json\",\n",
    "            accept=\"application/json\"\n",
    "        )\n",
    "\n",
    "        # Parse the response\n",
    "        response_body = json.loads(invoke_response['body'].read().decode('utf-8'))\n",
    "\n",
    "        if \"anthropic\" in model_id.lower():\n",
    "            generated_answer = response_body.get('content', [{}])[0].get(\"text\", \"\")\n",
    "        elif \"amazon.titan\" in model_id.lower():\n",
    "            generated_answer = response_body.get('results', [{}])[0].get(\"outputText\", '')\n",
    "        elif \"meta.llama\" in model_id.lower():\n",
    "            generated_answer = response_body.get('generation', '')\n",
    "        else:\n",
    "            generated_answer = \"Error: Could not parse response from the model.\"\n",
    "\n",
    "        # Final return\n",
    "        return {\n",
    "            \"query\": user_query,\n",
    "            \"retrieved_passages\": retrieved_passages,\n",
    "            \"generated_answer\": generated_answer,\n",
    "            \"model_used\": model_id\n",
    "        }\n",
    "    # Titan Embeddings G1 - Textv1.2\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"error\": str(e),\n",
    "            \"query\": user_query,\n",
    "            \"knowledge_base_id\": knowledge_base_id,\n",
    "            \"retrieved_passages\": [],\n",
    "            \"model_id\": model_id\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19a268cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Id is : amazon.titan-embed-text-v1\n",
      "Inside Amazon Titan Model\n",
      "\n",
      "============================================================\n",
      "Query: What is the Disciplinary Process of the company?\n",
      "\n",
      "No retrieved information found.\n",
      "\n",
      "Generated Answer:\n",
      " \n"
     ]
    }
   ],
   "source": [
    "##Retrievel Example\n",
    "# Define a sample knowledge base ID - This would be a real ID in a production scenario\n",
    "sample_kb_id = \"GIVL72SHRJ\"  # Replace with your actual knowledge base ID\n",
    "#sample_kb_id = \"ZHJZPXTKEV\"\n",
    "# sample_kb_id = \"KU4HIUJJNS\"  \n",
    "# sample_kb_id = \"KU4HIUJJNS\"\n",
    "print(f\"Model Id is : {model_id}\")\n",
    "# Test with a question that should be answerable from our knowledge base\n",
    "# query = \"What type of wellness programs are run by company ?\"\n",
    "# query = 'Who conducts annual workforce planning ?'\n",
    "# query = \"Who can avail Remote working benefit?\"\n",
    "# query = \"When medical certificate is required ?\"\n",
    "query = \"What is the Disciplinary Process of the company?\"\n",
    "# query = \"On what basis employee's compensation & benefits are revised or determined ?\"\n",
    "# query = \"What is the base of Annual Appraisal ?\"\n",
    "# query = \"What is the health and safety policy of the company.\"\n",
    "# query = \"How frequently salary is paid ?\"  # Uncomment to use this query\n",
    "result = query_hr_knowledge_base(query, sample_kb_id, model_id)\n",
    "if result is not None:\n",
    "    print(\"\\n\" + \"==\"*30)\n",
    "    print(f\"Query: {result.get('query', '')}\")\n",
    "    if result.get('retrieved_passages'):\n",
    "        print(f\"\\nRetrieved Information:\\n{result['retrieved_passages'][0]['content']}\")\n",
    "    else:\n",
    "        print(\"\\nNo retrieved information found.\")\n",
    "    if 'generated_answer' in result:\n",
    "        print(f\"\\nGenerated Answer:\\n {result['generated_answer']}\")\n",
    "    elif 'error' in result:\n",
    "        print(f\"\\nError:\\n {result['error']}\")\n",
    "    else:\n",
    "        print(\"\\nNo answer generated.\")\n",
    "## End of my experiment with RAG Model - I am tired now and it is 5.18 AM in the morning. I will continue later. ##\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AWSBedrock",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
